---
layout: archive
title: "news"
permalink: /news/
author_profile: true
redirect_from:
  - /resume
---

## Dip-NeRF: Depth-Based Anti-Aliased Neural Radiance Fields
### Shihao Qin   Jiangjian Xiao   Jianfei Ge  
<img  align="left" src="https://github.com/nimtecv/nimtecv.github.io/raw/master//images/qing.png"   width="200px" />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Neural radiation field (NeRF)-based novel view synthesis methods are gaining popularity for their ability to generate detailed and realistic images. However, most NeRF-based methods only use images to learn scene representations, ignoring the importance of depth information. The Zip-NeRF method has achieved impressive results in unbounded scenes by combining anti-aliasing techniques and mesh representations. However, the method requires a large number of input images and may perform poorly in complex scenes. Our method incorporates the advantages of Zip-NeRF and incorporates depth information to reduce the number of required images and solve the scale-free problem in borderless scenes. Experimental results show that our method effectively reduces the training time.And we can generate high-quality images and fine point cloud models using few images, even in complex scenes with numerous occlusions.
